{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14832d92-87bb-47f4-9f27-28f2238f0db9",
   "metadata": {
    "id": "14832d92-87bb-47f4-9f27-28f2238f0db9"
   },
   "source": [
    "## Deeper CNN\n",
    "### and more epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa4a0b-39e0-414b-bb22-ca5ce92f84f4",
   "metadata": {
    "id": "32aa4a0b-39e0-414b-bb22-ca5ce92f84f4"
   },
   "outputs": [],
   "source": [
    "## second iteration of deeper CNN to increase model complexity and reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hbOxF059pBqx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbOxF059pBqx",
    "outputId": "7a173f80-4c3c-46dc-ed77-ca3246c30d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move distribution in dataset: [22764. 23896. 24747. 26837. 24739. 23481. 22231.]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# Y = np.load('/Y_preprocessed.npy')\n",
    "# print(\"Move distribution in dataset:\", np.sum(Y, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZqgPFI7oyIJY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZqgPFI7oyIJY",
    "outputId": "ad33659c-d4a8-4255-de40-89153a002bd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.2590 - loss: 2.8855 - val_accuracy: 0.4369 - val_loss: 1.7533 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.4456 - loss: 1.7092 - val_accuracy: 0.5157 - val_loss: 1.4805 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5056 - loss: 1.5002 - val_accuracy: 0.5418 - val_loss: 1.3869 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.5382 - loss: 1.4066 - val_accuracy: 0.5672 - val_loss: 1.3127 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5561 - loss: 1.3544 - val_accuracy: 0.5838 - val_loss: 1.2706 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.5728 - loss: 1.3181 - val_accuracy: 0.5914 - val_loss: 1.2508 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 1.2973 - val_accuracy: 0.6020 - val_loss: 1.2423 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.5882 - loss: 1.2796 - val_accuracy: 0.6076 - val_loss: 1.2172 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 1.2696 - val_accuracy: 0.6135 - val_loss: 1.2002 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5962 - loss: 1.2577 - val_accuracy: 0.6110 - val_loss: 1.2097 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.6022 - loss: 1.2437 - val_accuracy: 0.6153 - val_loss: 1.1882 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 1.2358 - val_accuracy: 0.6153 - val_loss: 1.1866 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6078 - loss: 1.2249 - val_accuracy: 0.6167 - val_loss: 1.1787 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6108 - loss: 1.2170 - val_accuracy: 0.6224 - val_loss: 1.1720 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6135 - loss: 1.2153 - val_accuracy: 0.6223 - val_loss: 1.1642 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 1.2081 - val_accuracy: 0.6194 - val_loss: 1.1670 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6161 - loss: 1.2024 - val_accuracy: 0.6215 - val_loss: 1.1680 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 1.1943 - val_accuracy: 0.6262 - val_loss: 1.1611 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.6182 - loss: 1.1976 - val_accuracy: 0.6193 - val_loss: 1.1692 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6176 - loss: 1.1974 - val_accuracy: 0.6238 - val_loss: 1.1578 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6235 - loss: 1.1851 - val_accuracy: 0.6200 - val_loss: 1.1789 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6210 - loss: 1.1867 - val_accuracy: 0.6232 - val_loss: 1.1587 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m2108/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6234 - loss: 1.1820\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.6234 - loss: 1.1820 - val_accuracy: 0.6225 - val_loss: 1.1591 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6412 - loss: 1.1144 - val_accuracy: 0.6434 - val_loss: 1.0747 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 1.0605 - val_accuracy: 0.6414 - val_loss: 1.0594 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6581 - loss: 1.0383 - val_accuracy: 0.6397 - val_loss: 1.0659 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6619 - loss: 1.0286 - val_accuracy: 0.6439 - val_loss: 1.0589 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 1.0199 - val_accuracy: 0.6450 - val_loss: 1.0564 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6644 - loss: 1.0152 - val_accuracy: 0.6445 - val_loss: 1.0553 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6679 - loss: 1.0096 - val_accuracy: 0.6463 - val_loss: 1.0603 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 1.0087 - val_accuracy: 0.6471 - val_loss: 1.0522 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.6717 - loss: 1.0042 - val_accuracy: 0.6458 - val_loss: 1.0569 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 1.0019 - val_accuracy: 0.6434 - val_loss: 1.0574 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m2108/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.9999\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 1.0000 - val_accuracy: 0.6431 - val_loss: 1.0625 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6900 - loss: 0.9555 - val_accuracy: 0.6534 - val_loss: 1.0332 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.9199 - val_accuracy: 0.6498 - val_loss: 1.0345 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7035 - loss: 0.9060 - val_accuracy: 0.6510 - val_loss: 1.0263 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.8930 - val_accuracy: 0.6530 - val_loss: 1.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.8859 - val_accuracy: 0.6549 - val_loss: 1.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m2108/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7122 - loss: 0.8836\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7122 - loss: 0.8836 - val_accuracy: 0.6510 - val_loss: 1.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.8505 - val_accuracy: 0.6563 - val_loss: 1.0259 - learning_rate: 6.2500e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7320 - loss: 0.8296 - val_accuracy: 0.6562 - val_loss: 1.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.7377 - loss: 0.8176 - val_accuracy: 0.6537 - val_loss: 1.0359 - learning_rate: 6.2500e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2105/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.8060\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.8061 - val_accuracy: 0.6542 - val_loss: 1.0335 - learning_rate: 6.2500e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.7902 - val_accuracy: 0.6551 - val_loss: 1.0364 - learning_rate: 3.1250e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7510 - loss: 0.7784 - val_accuracy: 0.6558 - val_loss: 1.0398 - learning_rate: 3.1250e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.7484\n",
      "Final Validation Accuracy: 0.6558\n",
      "Training complete! Model saved as 'connect4_optimized_cnn.h5' and 'connect4_optimized_cnn.keras'.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_54c065d5-b0a0-4b2d-96f0-2e5c0ee92fdd\", \"connect4_optimized_cnn.h5\", 53314664)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_06156811-99b3-4a76-9cc6-6a647c726de9\", \"connect4_optimized_cnn.keras\", 53299085)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# import numpy as np\n",
    "# from google.colab import files  # For auto-downloading after training\n",
    "\n",
    "# # Load preprocessed data\n",
    "# X = np.load('X_preprocessed.npy')  # Shape: (num_samples, 6, 7, 2)\n",
    "# Y_onehot = np.load('Y_preprocessed.npy')\n",
    "\n",
    "# # Define an optimized deeper CNN model with Batch Normalization & L2 Regularization\n",
    "# model = Sequential([\n",
    "#     Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001), input_shape=(6,7,2)),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "#     MaxPooling2D(pool_size=(2,2), strides=(1,1)),\n",
    "#     Dropout(0.3),\n",
    "\n",
    "#     Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "#     BatchNormalization(),\n",
    "#     Flatten(),\n",
    "\n",
    "#     Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#     Dropout(0.4),\n",
    "#     Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#     Dense(7, activation='softmax')  # 7 possible moves\n",
    "# ])\n",
    "\n",
    "# # Compile the model with an adjusted learning rate\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)  # Slightly lower LR for better convergence\n",
    "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Callbacks for better training\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X, Y_onehot, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "# # Save the improved model in Colab-friendly formats\n",
    "# h5_model_path = \"connect4_optimized_cnn.h5\"\n",
    "# keras_model_path = \"connect4_optimized_cnn.keras\"\n",
    "\n",
    "# model.save(h5_model_path)\n",
    "# model.save(keras_model_path)\n",
    "\n",
    "# # Print final training & validation accuracy\n",
    "# train_acc = history.history['accuracy'][-1]\n",
    "# val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "# print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
    "# print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "# print(f\"Training complete! Model saved as '{h5_model_path}' and '{keras_model_path}'.\")\n",
    "\n",
    "# # 🔻 Automatically download files in Google Colab\n",
    "# files.download(h5_model_path)\n",
    "# files.download(keras_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pBygQiiD4s6Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pBygQiiD4s6Q",
    "outputId": "63f91d73-ca9f-4762-f8c3-d5faf6d6cac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.2631 - loss: 2.9065 - val_accuracy: 0.4282 - val_loss: 1.8088 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.4458 - loss: 1.7269 - val_accuracy: 0.5152 - val_loss: 1.4835 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.5059 - loss: 1.5032 - val_accuracy: 0.5527 - val_loss: 1.3703 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.5376 - loss: 1.4080 - val_accuracy: 0.5730 - val_loss: 1.2976 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.5565 - loss: 1.3572 - val_accuracy: 0.5782 - val_loss: 1.2739 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.5717 - loss: 1.3214 - val_accuracy: 0.5948 - val_loss: 1.2554 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.5805 - loss: 1.2978 - val_accuracy: 0.5934 - val_loss: 1.2510 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.5881 - loss: 1.2801 - val_accuracy: 0.6081 - val_loss: 1.2079 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.5939 - loss: 1.2637 - val_accuracy: 0.6056 - val_loss: 1.2130 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.5970 - loss: 1.2537 - val_accuracy: 0.6066 - val_loss: 1.2165 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 1.2471 - val_accuracy: 0.6128 - val_loss: 1.1986 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6053 - loss: 1.2319 - val_accuracy: 0.6180 - val_loss: 1.1751 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.6104 - loss: 1.2183 - val_accuracy: 0.6167 - val_loss: 1.1759 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6077 - loss: 1.2192 - val_accuracy: 0.6153 - val_loss: 1.1881 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.6093 - loss: 1.2177 - val_accuracy: 0.6210 - val_loss: 1.1666 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6128 - loss: 1.2082 - val_accuracy: 0.6205 - val_loss: 1.1790 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.6140 - loss: 1.2029 - val_accuracy: 0.6173 - val_loss: 1.1724 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6183 - loss: 1.1957 - val_accuracy: 0.6206 - val_loss: 1.1651 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.6170 - loss: 1.1909 - val_accuracy: 0.6240 - val_loss: 1.1570 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6195 - loss: 1.1887 - val_accuracy: 0.6251 - val_loss: 1.1518 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6213 - loss: 1.1878 - val_accuracy: 0.6204 - val_loss: 1.1567 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6203 - loss: 1.1842 - val_accuracy: 0.6241 - val_loss: 1.1461 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.6203 - loss: 1.1774 - val_accuracy: 0.6236 - val_loss: 1.1514 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6259 - loss: 1.1718 - val_accuracy: 0.6216 - val_loss: 1.1530 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6219 - loss: 1.1735 - val_accuracy: 0.6242 - val_loss: 1.1456 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6263 - loss: 1.1655 - val_accuracy: 0.6290 - val_loss: 1.1324 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.6261 - loss: 1.1660 - val_accuracy: 0.6247 - val_loss: 1.1433 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6254 - loss: 1.1623 - val_accuracy: 0.6258 - val_loss: 1.1415 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m2105/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6283 - loss: 1.1600\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6283 - loss: 1.1600 - val_accuracy: 0.6244 - val_loss: 1.1379 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.6450 - loss: 1.0946 - val_accuracy: 0.6414 - val_loss: 1.0628 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6556 - loss: 1.0451 - val_accuracy: 0.6438 - val_loss: 1.0505 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6612 - loss: 1.0275 - val_accuracy: 0.6433 - val_loss: 1.0432 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.6659 - loss: 1.0160 - val_accuracy: 0.6437 - val_loss: 1.0479 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.6684 - loss: 1.0078 - val_accuracy: 0.6433 - val_loss: 1.0487 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6653 - loss: 1.0081\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6653 - loss: 1.0081 - val_accuracy: 0.6421 - val_loss: 1.0518 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6796 - loss: 0.9686 - val_accuracy: 0.6485 - val_loss: 1.0207 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6931 - loss: 0.9301 - val_accuracy: 0.6489 - val_loss: 1.0202 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6990 - loss: 0.9184 - val_accuracy: 0.6492 - val_loss: 1.0190 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7029 - loss: 0.9048 - val_accuracy: 0.6503 - val_loss: 1.0222 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7052 - loss: 0.8970 - val_accuracy: 0.6501 - val_loss: 1.0227 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m2106/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7065 - loss: 0.8939\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.7065 - loss: 0.8939 - val_accuracy: 0.6477 - val_loss: 1.0228 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.7200 - loss: 0.8617 - val_accuracy: 0.6539 - val_loss: 1.0181 - learning_rate: 6.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 0.8410 - val_accuracy: 0.6498 - val_loss: 1.0226 - learning_rate: 6.2500e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7330 - loss: 0.8278 - val_accuracy: 0.6538 - val_loss: 1.0190 - learning_rate: 6.2500e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m2107/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.8270\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7324 - loss: 0.8270 - val_accuracy: 0.6511 - val_loss: 1.0227 - learning_rate: 6.2500e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7403 - loss: 0.8076 - val_accuracy: 0.6521 - val_loss: 1.0248 - learning_rate: 3.1250e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m2109/2109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.7926 - val_accuracy: 0.6517 - val_loss: 1.0283 - learning_rate: 3.1250e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 0.7420\n",
      "Final Validation Accuracy: 0.6517\n",
      "Training complete! Model saved as 'connect4_final_cnn.h5' and 'connect4_final_cnn.keras'.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a7ba94b0-95bf-4e98-be2e-ac20e3265d38\", \"connect4_final_cnn.h5\", 53317448)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_876778b0-a3a7-4237-acb2-6376ee410590\", \"connect4_final_cnn.keras\", 53304396)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from google.colab import files  # For auto-downloading after training\n",
    "\n",
    "# Load preprocessed data\n",
    "X = np.load('X_preprocessed.npy')  # Shape: (num_samples, 6, 7, 2)\n",
    "Y_onehot = np.load('Y_preprocessed.npy')\n",
    "\n",
    "# Define an optimized deeper CNN model with Batch Normalization & L2 Regularization\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001), input_shape=(6,7,2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=(1,1)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(7, activation='softmax')  # 7 possible moves\n",
    "])\n",
    "\n",
    "# Compile the model with an adjusted learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)  # Slightly lower LR for better convergence\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for better training\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X, Y_onehot, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "# Save the improved model in Colab-friendly formats\n",
    "h5_model_path = \"connect4_final_cnn.h5\"\n",
    "keras_model_path = \"connect4_final_cnn.keras\"\n",
    "\n",
    "model.save(h5_model_path)\n",
    "model.save(keras_model_path)\n",
    "\n",
    "# Print final training & validation accuracy\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Training complete! Model saved as '{h5_model_path}' and '{keras_model_path}'.\")\n",
    "\n",
    "# 🔻 Automatically download files in Google Colab\n",
    "files.download(h5_model_path)\n",
    "files.download(keras_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
